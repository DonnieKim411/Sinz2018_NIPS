{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nips2018.movie import data, parameters, models\n",
    "from nips2018.movie.analysis import performance\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import datajoint as dj\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "from itertools import product, chain\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import optim\n",
    "from attorch.train import early_stopping\n",
    "from nips2018.utils.measures import corr\n",
    "from contextlib import contextmanager\n",
    "from nips2018.movie.transforms import Subsample\n",
    "from attorch.dataloaders import RepeatsBatchSampler\n",
    "from nips2018.movie.analysis import performance\n",
    "\n",
    "def train_label(row, train=True):\n",
    "    if train:\n",
    "        h = row.data_hash\n",
    "    else:\n",
    "        h = row.test_data_hash\n",
    "        \n",
    "    if row.preproc_id == 1:\n",
    "        return 'Movie'\n",
    "    elif row.preproc_id == 2:\n",
    "        return 'Noise'\n",
    "    else:\n",
    "        return 'Movie & Noise'\n",
    "\n",
    "@contextmanager\n",
    "def silence():\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = open('/dev/null', 'w')\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        sys.stdout = old_stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group_id=17\n",
    "# animal_id = 17358\n",
    "# session=5\n",
    "# scan_idx=3\n",
    "\n",
    "group_id=20\n",
    "animal_id = 17797\n",
    "session=8\n",
    "scan_idx=5\n",
    "\n",
    "\n",
    "key = (models.Encoder() & dict(\n",
    "                core_hash='22d11147b37e3947e7d1034cc00d402c',\n",
    "                ro_hash='bf00321c11e46d68d4a42653a725969d', \n",
    "#                 ro_hash='2e577c259dd5629677a353f43ab528fb', # more regularization\n",
    "                data_hash='a4ecafc831670c7744ffe22320df77b7',\n",
    "                train_hash='624f62a2ef01d39f6703f3491bb9242b', \n",
    "                group_id=group_id)).fetch1(\"KEY\")\n",
    "\n",
    "base_data = [dict(group_id=key['group_id'], animal_id=animal_id, session=session, scan_idx=scan_idx)]\n",
    "scan_name = lambda i,j: '{animal_id}-{session}-{scan_idx}-{}'.format(j, **base_data[i])\n",
    "rokey = lambda i,j: 'group{group_id:03d}-{animal_id}-{session}-{scan_idx}-{}'.format(j, **base_data[i])\n",
    "scan_restr = \\\n",
    "    lambda i,j:  'animal_id={animal_id} and session={session} and scan_idx={scan_idx} and preproc_id={}'.format(\n",
    "                j, **base_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with silence():\n",
    "    model = models.Encoder().load_model(key)\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with silence():\n",
    "    data, loaders = parameters.DataConfig().load_data(key, tier='test')\n",
    "A = set(loaders[rokey(0,1)].sampler.indices)\n",
    "B =  set(loaders[rokey(0,2)].sampler.indices)\n",
    "assert len(A & B) == 0, 'indices overlap'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_id=17 # 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_scores(group_id, source):\n",
    "    tdh = \"5253599d3dceed531841271d6eeba9c5\" if source == \"Movies\" else \"6c0290da908317e55c4baf92e379d651\"\n",
    "    rel = (performance.ReadoutConvexComination.Scores() & 'test_data_hash=\"{}\"'.format(tdh) & dict(group_id=group_id))\n",
    "    l_mov, l_noise, pearson, poisson = rel.fetch('lambda_movies','lambda_noise', 'pearson', 'poisson', order_by=\"lambda_movies ASC, lambda_noise ASC\")\n",
    "    l_mov = np.fromiter(map(float, l_mov), dtype=float)\n",
    "    l_noise = np.fromiter(map(float, l_noise), dtype=float)\n",
    "    l_mov, l_noise, pearson, poisson = map(lambda x: x.reshape((11, 11)), [l_mov, l_noise, pearson, poisson])\n",
    "    return l_mov, l_noise, pearson, poisson\n",
    "\n",
    "\n",
    "l_mov, l_noise, pearson_noise, poisson_noise = load_scores(group_id, \"Noise\")\n",
    "l_mov, l_noise, pearson_nat, poisson_nat = load_scores(group_id, \"Movies\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('paper', font_scale=1.5)\n",
    "cmap = sns.diverging_palette(220, 20, as_cmap=True)\n",
    "with sns.axes_style('whitegrid'):\n",
    "    fig, ax = plt.subplots(2,2, figsize=(5, 5), dpi=100)\n",
    "\n",
    "def plotit(ax, l_mov, l_noise, M):\n",
    "    h = ax.pcolormesh(l_mov, l_noise, M, cmap=cmap, shading='gouraud', zorder=-10)\n",
    "    ax.set_xlabel(r'$\\lambda_{movies}$')\n",
    "    ax.set_ylabel(r'$\\lambda_{noise}$')\n",
    "    ax.grid(zorder=10, color='darkslategray', linestyle='--')\n",
    "    ax.set_aspect(1)\n",
    "    ax.set_xticks(np.linspace(0,1,3))\n",
    "    ax.set_yticks(np.linspace(0,1,3))\n",
    "    ax.set_xlim((0,1))\n",
    "    ax.set_ylim((0,1))\n",
    "    \n",
    "plotit(ax[0, 0], l_mov, l_noise, poisson_noise)\n",
    "plotit(ax[0, 1], l_mov, l_noise, poisson_nat)\n",
    "plotit(ax[1, 0], l_mov, l_noise, pearson_noise)\n",
    "plotit(ax[1, 1], l_mov, l_noise, pearson_nat)\n",
    "ax[0,0].set_title('on noise data')\n",
    "ax[0,1].set_title('on movie data')\n",
    "ax[1,1].text(1.2, 0.5, 'Pearson correlation', horizontalalignment='center',verticalalignment='center', transform=ax[1,1].transAxes, rotation=-90)\n",
    "ax[0,1].text(1.2, 0.5, 'Poisson loss', horizontalalignment='center',verticalalignment='center', transform=ax[0,1].transAxes, rotation=-90)\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(left=.15, right=.9, bottom=.1)\n",
    "fig.savefig('figures/loss_surface_group{group_id}.png'.format(group_id=group_id), dpi=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
