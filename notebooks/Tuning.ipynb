{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nips2018.movie import data, parameters, models\n",
    "from nips2018.movie.analysis import performance\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import datajoint as dj\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nips2018.movie.analysis import tuning\n",
    "from contextlib import contextmanager\n",
    "import pycircstat as circ\n",
    "from config import movie_vs_noise_cmap, fix_axis, scan_order, scan_cmap, performance_yticks, performance_ylim, strike\n",
    "from skimage.transform import resize\n",
    "from nips2018.movie import oracle\n",
    "\n",
    "@contextmanager\n",
    "def silence():\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = open('/dev/null', 'w')\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        sys.stdout = old_stdout\n",
    "        \n",
    "groups = [21, 22, 23]\n",
    "group_constr = 'group_id in ({})'.format(','.join([str(e) for e in groups]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Difference in preferred orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_ids = [21,22,23]\n",
    "group_constr = 'group_id in ({})'.format(','.join(tuple(map(str, group_ids))))\n",
    "base = {'core_hash': '22d11147b37e3947e7d1034cc00d402c', # 12 x 36\n",
    "     'seed': 2606,\n",
    "     'train_hash': '624f62a2ef01d39f6703f3491bb9242b', # batchsize=8 stop gradient\n",
    "     'ro_hash':'bf00321c11e46d68d4a42653a725969d', # 2 and 4 \n",
    "    }\n",
    "network_configs0 = dj.AndList([\n",
    "    base,\n",
    "    'mod_hash in (\"4954311aa3bebb347ebf411ab5198890\")',\n",
    "    'shift_hash in (\"64add03e1462b7413b59812d446aee9f\")',\n",
    "    'data_hash in (\"5253599d3dceed531841271d6eeba9c5\", \"6c0290da908317e55c4baf92e379d651\")',\n",
    "    group_constr\n",
    "])\n",
    "network_configs1 = dj.AndList([\n",
    "    base,\n",
    "    'mod_hash in (\"bafd7322c6e97d25b6299b5d6fe8920b\")',\n",
    "    'shift_hash in (\"bafd7322c6e97d25b6299b5d6fe8920b\")',\n",
    "    'data_hash in (\"5253599d3dceed531841271d6eeba9c5\", \"6c0290da908317e55c4baf92e379d651\")',\n",
    "    group_constr\n",
    "])\n",
    "network_configs = [network_configs0, network_configs1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning.MonetResponse().populate(network_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning.MonetOri().populate(network_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning.MonetOri() & network_configs & dict(ori_type='ori')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orientation Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_cell = tuning.Ori.Cell() & dict(stimulus_type=\"stimulus.Monet2\", ori_type='ori', spike_method=5, segmentation_method=3, ori_version=3) & 'selectivity > .2 and r2 > 0.005' & (data.MovieMultiDataset.Member() & group_constr)\n",
    "df_cell = pd.DataFrame(rel_cell.fetch())\n",
    "rel_model = tuning.MonetOri.Cell().proj(model_angle='angle', train_data='IF(data_hash = \"5253599d3dceed531841271d6eeba9c5\", \"movies\", \"noise\")') & network_configs\n",
    "df_model = pd.DataFrame(rel_model.fetch())\n",
    "df_model['model'] = ['full' if not (r.shift_hash == 'bafd7322c6e97d25b6299b5d6fe8920b' and (r.mod_hash == 'bafd7322c6e97d25b6299b5d6fe8920b')) else strike('shifter/modulator') for _, r in df_model.iterrows()]\n",
    "df = df_cell.merge(df_model, on=['animal_id', 'session', 'scan_idx', 'unit_id', 'ori_type'])\n",
    "df = df.drop([e for e in df.columns if 'hash' in e], axis=1)\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['scan'] = ['{animal_id}-{session}-{scan_idx}'.format(**r.to_dict()) for _, r in df.iterrows()]\n",
    "df[r'$\\Delta \\phi$'] = circ.cdiff(2 * df.angle, 2 * df.model_angle) / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('paper', font_scale=1.2)\n",
    "\n",
    "sns.set_palette(scan_cmap)\n",
    "g = sns.factorplot(\"model\",  r'$\\Delta \\phi$', hue='scan', data=df, kind='lv', \n",
    "                   col='train_data', legend=False, order=[strike('shifter/modulator'), \"full\"])\n",
    "g.fig.set_dpi(150)\n",
    "g.axes[0,0].set_yticks([-np.pi/2,-np.pi/4,0,np.pi/4,np.pi/2])\n",
    "g.axes[0,0].set_yticklabels([r'$-\\frac{\\pi}{2}$', r'$-\\frac{\\pi}{4}$', '0', r'$\\frac{\\pi}{4}$', r'$\\frac{\\pi}{2}$'])\n",
    "# g.set_xlabels(\"\")\n",
    "g.axes[0,0].set_ylabel(r'$\\Delta$ preferred orientation')\n",
    "g.axes[0,0].yaxis.grid(linestyle=':', zorder=-20, lw=1)\n",
    "g.axes[0,1].yaxis.grid(linestyle=':', zorder=-20, lw=1)\n",
    "g.axes[0,1].legend(ncol=1)\n",
    "g.set_titles(\"{col_name}\")\n",
    "g.fig.set_size_inches((5,5))\n",
    "sns.despine(trim=True)\n",
    "g.fig.subplots_adjust(bottom=.2, left=.125)\n",
    "g.fig.savefig('figures/delta_ori_lv.png', dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Shifter vs. Modulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import levene\n",
    "\n",
    "def test(d):\n",
    "    return pd.Series({'p-value':levene(d['full'], d[strike('shifter/modulator')])[1]})\n",
    "\n",
    "df2 = df.groupby(['train_data', 'scan', 'model'])[r'$\\Delta \\phi$'].std().unstack('model')\n",
    "df2['ratio'] = df2.loc[:, strike('shifter/modulator')]/df2.loc[:, 'full']\n",
    "\n",
    "df3 = df.set_index(['train_data', 'scan','unit_id',  'model'])[r'$\\Delta \\phi$'].unstack('model').reset_index()\n",
    "df3 = df3.groupby(['train_data', 'scan']).apply(test)\n",
    "df2['p-value'] = df3['p-value']\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direction tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning.MonetOri() & network_configs & dict(ori_type='dir', ori_version=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rel_cell = tune.Ori.Cell() & dict(stimulus_type=\"stimulus.Monet2\", ori_type='dir', spike_method=5, segmentation_method=3, ori_version=3) & '1/(2/selectivity-1) > .1 and r2 > 0.002' & (data.MovieMultiDataset.Member() & group_constr)\n",
    "rel_cell = tuning.Ori.Cell() & dict(stimulus_type=\"stimulus.Monet2\", ori_type='dir', spike_method=5, segmentation_method=3, ori_version=3) & 'selectivity > .1 and r2 > 0.002' & (data.MovieMultiDataset.Member() & group_constr)\n",
    "df_cell = pd.DataFrame(rel_cell.fetch())\n",
    "rel_model = tuning.MonetOri.Cell().proj(model_angle='angle', train_data='IF(data_hash = \"5253599d3dceed531841271d6eeba9c5\", \"movies\", \"noise\")') & network_configs\n",
    "df_model = pd.DataFrame(rel_model.fetch())\n",
    "df_model['model'] = ['full' if not (r.shift_hash == 'bafd7322c6e97d25b6299b5d6fe8920b' and (r.mod_hash == 'bafd7322c6e97d25b6299b5d6fe8920b')) else strike('shifter/modulator') for _, r in df_model.iterrows()]\n",
    "df = df_cell.merge(df_model, on=['animal_id', 'session', 'scan_idx', 'unit_id', 'ori_type'])\n",
    "df = df.drop([e for e in df.columns if 'hash' in e], axis=1)\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[r'$\\Delta \\phi$'] = circ.cdiff(df.angle, df.model_angle) \n",
    "df['scan'] = ['{animal_id}-{session}-{scan_idx}'.format(**r.to_dict()) for _, r in df.iterrows()]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('paper', font_scale=1.2)\n",
    "sns.set_palette(scan_cmap)\n",
    "g = sns.factorplot(\"model\",  r'$\\Delta \\phi$', hue='scan', data=df,  kind='lv', col='train_data', legend=False, order=[strike('shifter/modulator'), \"full\"])\n",
    "g.fig.set_dpi(150)\n",
    "g.axes[0,0].set_yticks(np.linspace(-1, 1, 5) * np.pi)\n",
    "g.axes[0,0].set_yticklabels([r'$-\\pi$', r'$-\\frac{3\\pi}{4}$', r'$-\\frac{\\pi}{2}$',  r'$-\\frac{\\pi}{4}$', '0',  r'$\\frac{\\pi}{4}$', r'$\\frac{\\pi}{2}$', r'$\\frac{3\\pi}{4}$', r'$\\pi$'][::2])\n",
    "g.axes[0,0].set_ylabel(r'$\\Delta$ preferred direction')\n",
    "g.axes[0,0].yaxis.grid(linestyle=':', zorder=-20, lw=1)\n",
    "g.axes[0,1].yaxis.grid(linestyle=':', zorder=-20, lw=1)\n",
    "g.axes[0,1].legend(ncol=1, loc='upper right')\n",
    "g.set_titles(\"{col_name}\")\n",
    "g.fig.set_size_inches((5,5))\n",
    "g.fig.subplots_adjust(bottom=.2, left=.125)\n",
    "\n",
    "sns.despine(trim=True)\n",
    "g.fig.savefig('figures/delta_dir_lv.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import levene\n",
    "\n",
    "def test(d):\n",
    "    return pd.Series({'p-value':levene(d['full'], d[strike('shifter/modulator')])[1]})\n",
    "\n",
    "df2 = df.groupby(['train_data', 'scan', 'model'])[r'$\\Delta \\phi$'].std().unstack('model')\n",
    "df2['ratio'] = df2.loc[:, strike('shifter/modulator')]/df2.loc[:, 'full']\n",
    "\n",
    "df3 = df.set_index(['train_data', 'scan','unit_id',  'model'])[r'$\\Delta \\phi$'].unstack('model').reset_index()\n",
    "df3 = df3.groupby(['train_data', 'scan']).apply(test)\n",
    "df2['p-value'] = df3['p-value']\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot tuning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_ids = [21, 22, 23]\n",
    "group_constr = 'group_id in ({})'.format(','.join(tuple(map(str, group_ids))))\n",
    "\n",
    "network_config = dj.AndList([\n",
    "    {    'core_hash': '22d11147b37e3947e7d1034cc00d402c', # 12 x 36\n",
    "         'mod_hash': '4954311aa3bebb347ebf411ab5198890',\n",
    "         'seed': 2606,\n",
    "         'shift_hash': '64add03e1462b7413b59812d446aee9f',\n",
    "         'train_hash': '624f62a2ef01d39f6703f3491bb9242b', # batchsize=8 stop gradient\n",
    "         'ro_hash':'bf00321c11e46d68d4a42653a725969d', # 2 and 4 \n",
    "        },\n",
    "    'data_hash in (\"5253599d3dceed531841271d6eeba9c5\", \"6c0290da908317e55c4baf92e379d651\")',\n",
    "    group_constr\n",
    "])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning.MonetCurve() & network_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constr_cell = tuning.Ori.Cell() & dict(stimulus_type=\"stimulus.Monet2\", ori_type='dir', spike_method=5, segmentation_method=3) \\\n",
    "                              & '1/(2/selectivity - 1) > .2 and r2 > 0.005' & (data.MovieMultiDataset.Member() & group_constr)\n",
    "rel_curve = tuning.DirCurve() * tuning.DirCurve.Cell() * constr_cell\n",
    "df_curve = pd.DataFrame(rel_curve.fetch(order_by='r2 DESC'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_model = (tuning.MonetCurve() * tuning.MonetCurve.Cell() * models.Encoder.UnitTestScores()).proj(\n",
    "            'pearson', \n",
    "            model_directions='directions', \n",
    "            model_curve='curve', \n",
    "            train_data='IF(data_hash = \"5253599d3dceed531841271d6eeba9c5\", \"movies\", \"noise\")')  & network_config\n",
    "df_model = pd.DataFrame(rel_model.fetch())\n",
    "\n",
    "df = df_curve.merge(df_model, on=['animal_id', 'session', 'scan_idx', 'unit_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_rank(df):\n",
    "    df1 = df[df.train_data == \"movies\"].sort_values(\"unit_id\")\n",
    "    df2 = df[df.train_data == \"noise\"].sort_values(\"unit_id\")\n",
    "    rank = np.array(np.argsort(-df1.pearson))\n",
    "    df1['score_rank'] = rank\n",
    "    df2['score_rank'] = rank\n",
    "    tmp =  pd.concat([df1, df2]).drop(['animal_id', 'session', 'scan_idx'], axis=1)\n",
    "    return tmp\n",
    "\n",
    "df2 = df.groupby(['animal_id', 'session', 'scan_idx']).apply(get_movie_rank).reset_index()\n",
    "df2['scan'] = ['{animal_id}-{session}-{scan_idx}'.format(**r.to_dict()) for _, r in df2.iterrows()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2.score_rank < N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 12\n",
    "sns.set_palette(scan_cmap)\n",
    "sns.set_context('paper', font_scale=2)\n",
    "def plot_ori(d, dm, c, cm, zscore=True, **kwargs):\n",
    "    label = kwargs.pop('label')\n",
    "    kwargs.pop('color')\n",
    "\n",
    "    c = c.iloc[0]\n",
    "    cm = cm.iloc[0]\n",
    "    if zscore:\n",
    "        c = (c - c.mean())/c.std()\n",
    "        cm = (cm - cm.mean())/cm.std()\n",
    "    if label == 'movies':\n",
    "        plt.plot(d.iloc[0], c, '--', color='darkslategray', label='neuron', zorder=-10, **kwargs)\n",
    "    plt.plot(dm.iloc[0], cm, label=label, color=sns.xkcd_rgb['cerulean blue'] if label == 'noise' else sns.xkcd_rgb['deep pink'],  **kwargs)\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticks([0,np.pi/2,np.pi, 3* np.pi/2,2*np.pi])\n",
    "    ax.set_xticklabels(['0', r'$\\frac{\\pi}{2}$', r'$\\pi$', r'$\\frac{3\\pi}{2}$', r'$2\\pi$'])\n",
    "\n",
    "g = sns.FacetGrid(df2[df2.score_rank < N], row='scan', col='score_rank', hue='train_data', margin_titles=False, col_order=np.arange(12))\n",
    "g.map(plot_ori, \"directions\",  \"model_directions\", \"curve\", \"model_curve\", lw=3)\n",
    "g.set_axis_labels(\"directions\", \"z-scored mean\\nresponse\")\n",
    "g.set_titles(template=\"\", col_template=\"\", row_template=\"\")\n",
    "g._margin_titles = True\n",
    "g.set_titles(template=\"\", col_template=\"\", row_template=\"{row_var} {row_name}\")\n",
    "leg = g.axes[0,0].legend(loc=\"upper left\", ncol=1)\n",
    "leg.get_frame().set_linewidth(0.0)\n",
    "sns.despine(trim=True)\n",
    "# g.fig.tight_layout()\n",
    "g.fig.subplots_adjust(wspace=.05, hspace=.05)\n",
    "g.fig.savefig('figures/direction_tuning.png', dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Receptive fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_ids = [21, 22, 23]\n",
    "group_constr = 'group_id in ({})'.format(','.join(tuple(map(str, group_ids))))\n",
    "\n",
    "network_config = dj.AndList([\n",
    "    {    'core_hash': '22d11147b37e3947e7d1034cc00d402c', # 12 x 36\n",
    "         'mod_hash': '4954311aa3bebb347ebf411ab5198890',\n",
    "         'seed': 2606,\n",
    "         'shift_hash': '64add03e1462b7413b59812d446aee9f',\n",
    "         'train_hash': '624f62a2ef01d39f6703f3491bb9242b', # batchsize=8 stop gradient\n",
    "         'ro_hash':'bf00321c11e46d68d4a42653a725969d', # 2 and 4 \n",
    "        },\n",
    "    'data_hash in (\"5253599d3dceed531841271d6eeba9c5\", \"6c0290da908317e55c4baf92e379d651\")',\n",
    "    group_constr\n",
    "])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning.STA() & network_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constr_cell = tuning.NeuroSTAQual()  & dict(stimulus_type=\"stimulus.Monet2\", spike_method=5, segmentation_method=3) \\\n",
    "                              & 'snr > 6' & (data.MovieMultiDataset.Member() & group_constr)\n",
    "rel_sta_neuron = tuning.NeuroSTA.Map() * constr_cell\n",
    "df_sta = pd.DataFrame(rel_sta_neuron.fetch(order_by='snr DESC'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_model = (tuning.STA() * tuning.STA.Map() * models.Encoder.UnitTestScores()).proj(\n",
    "            'pearson', \n",
    "            model_map='map', \n",
    "            train_data='IF(data_hash = \"5253599d3dceed531841271d6eeba9c5\", \"movies\", \"noise\")')  & network_config\n",
    "df_model = pd.DataFrame(rel_model.fetch())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = pd.DataFrame(df_model[df_model.train_data == \"movies\"])\n",
    "tmp2 = pd.DataFrame(df_model[df_model.train_data == \"noise\"])\n",
    "df3 = tmp1.merge(tmp2, on=['animal_id', 'session', 'scan_idx','unit_id'], suffixes=('_movies', '_noise'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_sta.merge(df3, on=['animal_id', 'session', 'scan_idx', 'unit_id'])\n",
    "\n",
    "def get_rank(df):\n",
    "    rank = np.array(np.argsort(-df.pearson_movies))\n",
    "    df['score_rank'] = rank\n",
    "    return df\n",
    "\n",
    "df2 = df.groupby(['animal_id', 'session', 'scan_idx']).apply(get_rank).reset_index()\n",
    "df2['scan'] = ['{animal_id}-{session}-{scan_idx}'.format(**r.to_dict()) for _, r in df2.iterrows()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def preprocess(rf, lag):\n",
    "    assert len(rf) == 1\n",
    "    rf = rf.iloc[0]\n",
    "    rf = rf[..., :lag].mean(axis=-1)\n",
    "    return rf\n",
    "    \n",
    "\n",
    "N = 12\n",
    "lag = 3\n",
    "sns.set_context('paper', font_scale=1.0)\n",
    "def plot_rf(rf_natural, rf_neuron, rf_noise, lag=1, v=65, g=7, **kwargs):\n",
    "    kwargs.pop('color')\n",
    "    rf_natural, rf_neuron, rf_noise = map(partial(preprocess, lag=lag), [rf_natural, rf_neuron, rf_noise])\n",
    "\n",
    "    if not rf_neuron.shape[0] / rf_natural.shape[0] == rf_neuron.shape[1] / rf_natural.shape[1]:\n",
    "        if rf_neuron.shape == (126, 216):\n",
    "            rf_neuron = rf_neuron[4:4 + 117, 4:4 + 208]\n",
    "   \n",
    "    shape = rf_neuron.shape\n",
    "    ax = plt.gca()\n",
    "    tmp1 = resize(rf_natural, shape, preserve_range=True) \n",
    "    tmp2 = resize(rf_noise, shape, preserve_range=True) \n",
    "    tmp = np.vstack((tmp1, rf_neuron, tmp2))\n",
    "    ax.matshow(tmp, vmin=-v, vmax=v, **kwargs)\n",
    "    y, x = shape\n",
    "    yt = np.linspace(0,3*y,3*g + 1)\n",
    "    ax.set_xticks(np.linspace(0,x,g+1))\n",
    "    ax.set_yticks(yt)\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.plot([0,x], [y,y], '--', color='darkslategray',lw=.5)\n",
    "    ax.plot([0,x], [2 * y,2 * y], '--',color='darkslategray',lw=.5)\n",
    "    ax.axis('tight')\n",
    "    ax.axis([0,x+1, -1,3*y])\n",
    "    ax.grid(lw=.5)\n",
    "    \n",
    "\n",
    "with sns.axes_style('whitegrid'):\n",
    "    g = sns.FacetGrid(df2[df2.score_rank < N], row='scan', col='score_rank', margin_titles=False)\n",
    "    g.map(plot_rf, \"model_map_movies\", \"map\", \"model_map_noise\", lag=lag, cmap='bwr', v=90)\n",
    "g.set_axis_labels(\"\", \"\")\n",
    "g.set_titles(template=\"\", col_template=\"\", row_template=\"\")\n",
    "# g._margin_titles = True\n",
    "# g.set_titles(template=\"\", col_template=\"\", row_template=\"{row_var} {row_name}\")\n",
    "\n",
    "for ax, rowlab in zip(g.axes[:, -1], g.row_names):\n",
    "    ax.text(1.1, 0.5, 'scan ' + rowlab, horizontalalignment='center',verticalalignment='center', transform=ax.transAxes, rotation=-90)\n",
    "\n",
    "g.set_ylabels('movies | neuron | noise')\n",
    "# leg = g.axes[0,0].legend(loc=\"upper left\")\n",
    "# leg.get_frame().set_linewidth(0.0)\n",
    "sns.despine(left=True, bottom=True)\n",
    "\n",
    "g.fig.set_size_inches((14,6))\n",
    "g.fig.subplots_adjust(left=.05, hspace=.1, wspace=.1, right=0.95)\n",
    "g.fig.savefig('figures/receptive_fields.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
